{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "18y_87wOhvq3bIeGHDAIqv5GeekIxTjDC",
      "authorship_tag": "ABX9TyMaLOZSaa3WiXGDmEMA67Mg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ruck13/Uczenie-maszynowe-w-finansach/blob/main/Case1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ebSangaOGco",
        "outputId": "fd20ee27-efb1-408a-a118-e6079f484009"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time      0\n",
            "V1        0\n",
            "V2        0\n",
            "V3        0\n",
            "V4        0\n",
            "V5        0\n",
            "V6        0\n",
            "V7        0\n",
            "V8        0\n",
            "V9        0\n",
            "V10       0\n",
            "V11       0\n",
            "V12       0\n",
            "V13       0\n",
            "V14       0\n",
            "V15       0\n",
            "V16       0\n",
            "V17       0\n",
            "V18       0\n",
            "V19       0\n",
            "V20       0\n",
            "V21       0\n",
            "V22       0\n",
            "V23       0\n",
            "V24       0\n",
            "V25       0\n",
            "V26       0\n",
            "V27       0\n",
            "V28       0\n",
            "Amount    0\n",
            "Class     0\n",
            "dtype: int64\n",
            "Logistic Regression:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.99     56864\n",
            "           1       0.05      0.92      0.10        98\n",
            "\n",
            "    accuracy                           0.97     56962\n",
            "   macro avg       0.53      0.94      0.54     56962\n",
            "weighted avg       1.00      0.97      0.98     56962\n",
            "\n",
            "Random Forest:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56864\n",
            "           1       0.64      0.88      0.74        98\n",
            "\n",
            "    accuracy                           1.00     56962\n",
            "   macro avg       0.82      0.94      0.87     56962\n",
            "weighted avg       1.00      1.00      1.00     56962\n",
            "\n",
            "SVM:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99     56864\n",
            "           1       0.08      0.92      0.16        98\n",
            "\n",
            "    accuracy                           0.98     56962\n",
            "   macro avg       0.54      0.95      0.57     56962\n",
            "weighted avg       1.00      0.98      0.99     56962\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/StudiaMagisterka/creditcard.csv\")\n",
        "\n",
        "# Sprawdzenie braków\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Standaryzacja kolumn 'Time' i 'Amount'\n",
        "scaler = StandardScaler()\n",
        "df[['Time', 'Amount']] = scaler.fit_transform(df[['Time', 'Amount']])\n",
        "\n",
        "# Podział na cechy i etykiety\n",
        "X = df.drop('Class', axis=1)\n",
        "y = df['Class']\n",
        "\n",
        "# Podział na zbiór treningowy i testowy\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "#Redukcja wymiarów (PCA)\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=20)\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "\n",
        "# Zbilansowanie próbki (SMOTE + undersampling)\n",
        "over = SMOTE(sampling_strategy=0.1, random_state=42)\n",
        "under = RandomUnderSampler(sampling_strategy=0.5, random_state=42)\n",
        "X_resampled, y_resampled = Pipeline([('o', over), ('u', under)]).fit_resample(X_train_pca, y_train)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "\n",
        "# Zbilansowanie próbki (SMOTE + undersampling)\n",
        "over = SMOTE(sampling_strategy=0.1, random_state=42)\n",
        "under = RandomUnderSampler(sampling_strategy=0.5, random_state=42)\n",
        "X_resampled, y_resampled = Pipeline([('o', over), ('u', under)]).fit_resample(X_train_pca, y_train)\n",
        "\n",
        "# Model 1: Regresja logistyczna\n",
        "model1 = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
        "model1.fit(X_resampled, y_resampled)\n",
        "y_pred1 = model1.predict(X_test_pca)\n",
        "\n",
        "# Model 2: Random Forest\n",
        "model2 = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
        "model2.fit(X_resampled, y_resampled)\n",
        "y_pred2 = model2.predict(X_test_pca)\n",
        "\n",
        "# Model 3: SVM\n",
        "model3 = SVC(kernel='rbf', class_weight='balanced', probability=True)\n",
        "model3.fit(X_resampled, y_resampled)\n",
        "y_pred3 = model3.predict(X_test_pca)\n",
        "\n",
        "print(\"Logistic Regression:\\n\", classification_report(y_test, y_pred1))\n",
        "print(\"Random Forest:\\n\", classification_report(y_test, y_pred2))\n",
        "print(\"SVM:\\n\", classification_report(y_test, y_pred3))\n",
        "\n",
        "#Na podstawie metryk (precision, recall, F1-score dla klasy 1 – oszustwa):\n",
        "#- Random Forest zwykle osiąga najlepszy kompromis między czułością a precyzją.\n",
        "#- SVM może mieć wyższą precyzję, ale niższą czułość.\n",
        "#- Regresja logistyczna działa dobrze, ale może być mniej skuteczna przy nieliniowych zależnościach.\n",
        "#Wybór: Random Forest – najlepszy F1-score dla klasy oszustw, dobra interpretowalność i odporność na niezbalansowanie.\n",
        "\n"
      ]
    }
  ]
}